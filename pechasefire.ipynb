{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1408148,"sourceType":"datasetVersion","datasetId":823358},{"sourceId":7658896,"sourceType":"datasetVersion","datasetId":4465590}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Import Libraries and Load Tokenizer\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, AdamW, get_scheduler\nfrom datasets import load_dataset\nimport pandas as pd\nimport wandb\nfrom torch.cuda.amp import autocast, GradScaler\nimport gc\nfrom tqdm import tqdm\n\n# Initialize WandB in offline mode\nwandb.init(project=\"DeBERTa-Fake-News\", config={\"epochs\": 3, \"batch_size\": 32, \"lr\": 1e-5}, mode=\"offline\")\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\n# Free GPU cache\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load DeBERTa tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:31:30.542654Z","iopub.execute_input":"2025-03-29T15:31:30.542870Z","iopub.status.idle":"2025-03-29T15:31:58.750277Z","shell.execute_reply.started":"2025-03-29T15:31:30.542848Z","shell.execute_reply":"2025-03-29T15:31:58.749548Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c4a75b93ac74b1caac5753498997c65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ab28b8699b4101bffc8cbeca367d35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85693a71ee06437cbb2f869927db4a94"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Load Datasets\n# Load dataset from Hugging Face for pre-training\nds = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-v1\", split=\"train\")\npretrain_texts = ds[\"text\"][:int(0.05 * len(ds[\"text\"]))]  # Use 10% of Wikitext-103\npretrain_df = pd.DataFrame({\"text\": pretrain_texts, \"label\": [0] * len(pretrain_texts)})\n\n# Load dataset from CSV (WELFake) for fine-tuning\nwelfake_df = pd.read_csv(\"/kaggle/input/welfake-dataset-for-fake-news/WELFake_Dataset.csv\", usecols=[\"text\", \"label\"], dtype={\"label\": str})\n\n# Ensure labels are numeric & clean\nwelfake_df[\"label\"] = welfake_df[\"label\"].str.replace(r\"[^\\d]\", \"\", regex=True).str.strip()\nwelfake_df = welfake_df[welfake_df[\"label\"] != \"\"]  # Remove empty values\nwelfake_df[\"label\"] = welfake_df[\"label\"].astype(int)  # Convert to int for PyTorch\nprint(\"Data loading complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:32:01.367312Z","iopub.execute_input":"2025-03-29T15:32:01.367734Z","iopub.status.idle":"2025-03-29T15:32:18.081242Z","shell.execute_reply.started":"2025-03-29T15:32:01.367698Z","shell.execute_reply":"2025-03-29T15:32:18.080238Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0109c52f0424918a4e6bf3e765fe3ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/722k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b82310686704efaa359c328e89e8d73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10fe7176e15423884eb4b22fd1a1fcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0e68f1a15c14569acb883b7521adeec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/655k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e53efb1cb99647d098866b581604d41f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0aaa6997ffa43cca7876eb3237f06f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"749109ea80704bf983b5463377ea7b3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3396bb744ecf4a308babfe65f54183bc"}},"metadata":{}},{"name":"stdout","text":"Data loading complete!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Define Dataset Classes\nclass MLMDataset(Dataset):\n    def __init__(self, texts, max_len=128):\n        self.encodings = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n        self.labels = self.encodings.input_ids.clone()\n        rand = torch.rand(self.labels.shape)\n        mask_arr = (rand < 0.15) * (self.labels != tokenizer.pad_token_id) * (self.labels != tokenizer.cls_token_id) * (self.labels != tokenizer.sep_token_id)\n        self.encodings.input_ids[mask_arr] = tokenizer.mask_token_id\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return {key: val[idx] for key, val in self.encodings.items()}, self.labels[idx]\n\nclass FakeNewsDataset(Dataset):\n    def __init__(self, df, max_len=256):\n        self.labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n        self.encodings = tokenizer(df[\"text\"].astype(str).tolist(), padding=\"max_length\", truncation=True, \n                                   max_length=max_len, return_tensors=\"pt\")\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return {key: val[idx] for key, val in self.encodings.items() if key != \"token_type_ids\"}, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:32:24.770560Z","iopub.execute_input":"2025-03-29T15:32:24.770904Z","iopub.status.idle":"2025-03-29T15:32:24.783559Z","shell.execute_reply.started":"2025-03-29T15:32:24.770874Z","shell.execute_reply":"2025-03-29T15:32:24.782721Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Cell 4: Define DeBERTa Model\nclass DeBERTaClassifier(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_labels=2):\n        super(DeBERTaClassifier, self).__init__()\n        self.deberta = AutoModel.from_pretrained(model_name)\n        self.deberta.gradient_checkpointing_enable()\n        self.classifier = nn.Linear(self.deberta.config.hidden_size, num_labels)\n        self.mlm_head = nn.Linear(self.deberta.config.hidden_size, self.deberta.config.vocab_size)  # MLM head for pretraining\n    \n    def forward(self, input_ids, attention_mask, mlm=False):\n        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n        if mlm:\n            return self.mlm_head(outputs.last_hidden_state)\n        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:32:27.511409Z","iopub.execute_input":"2025-03-29T15:32:27.511836Z","iopub.status.idle":"2025-03-29T15:32:27.520769Z","shell.execute_reply.started":"2025-03-29T15:32:27.511803Z","shell.execute_reply":"2025-03-29T15:32:27.519735Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Cell 5: Initialize Model, Optimizer, and Scheduler\nmodel = DeBERTaClassifier().to(device)\noptimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Learning rate scheduler\nnum_training_steps = 3 * len(welfake_df) // 32  # Adjusted for batch size 32\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n\nscaler = GradScaler()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:32:30.477597Z","iopub.execute_input":"2025-03-29T15:32:30.478021Z","iopub.status.idle":"2025-03-29T15:32:48.350134Z","shell.execute_reply.started":"2025-03-29T15:32:30.477984Z","shell.execute_reply":"2025-03-29T15:32:48.348959Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea13f458bcb54c3e9058690448bada86"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n<ipython-input-5-17bdeab1d406>:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 6: Pre-training Loop\ndef pretrain_model(model, train_loader, epochs=1):\n    model.train()\n    mlm_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n    for epoch in range(epochs):\n        total_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Pretraining Epoch {epoch+1}\")\n        for batch in progress_bar:\n            inputs, labels = batch\n            inputs = {key: val.to(device) for key, val in inputs.items()}\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n                outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], mlm=True)\n                loss = mlm_criterion(outputs.view(-1, model.deberta.config.vocab_size), labels.view(-1))\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            total_loss += loss.item()\n            progress_bar.set_postfix(loss=total_loss / len(train_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:32:58.187434Z","iopub.execute_input":"2025-03-29T15:32:58.188545Z","iopub.status.idle":"2025-03-29T15:32:58.195920Z","shell.execute_reply.started":"2025-03-29T15:32:58.188514Z","shell.execute_reply":"2025-03-29T15:32:58.195027Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Cell 7: Run Pre-training\npretrain_dataset = MLMDataset(pretrain_texts)\npretrain_loader = DataLoader(pretrain_dataset, batch_size=32, shuffle=True)\npretrain_model(model, pretrain_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T15:33:00.559828Z","iopub.execute_input":"2025-03-29T15:33:00.560223Z"}},"outputs":[{"name":"stderr","text":"Pretraining Epoch 1:   9%|â–‰         | 267/2815 [12:45<2:04:50,  2.94s/it, loss=0.434]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Cell 8: Run Fine-tuning\ntrain_dataset = FakeNewsDataset(welfake_df)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntrain_model(model, train_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9: Save and Evaluate Model\ntorch.save(model.state_dict(), \"deberta_fakenews.pth\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}