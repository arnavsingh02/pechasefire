{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1408148,"sourceType":"datasetVersion","datasetId":823358},{"sourceId":7658896,"sourceType":"datasetVersion","datasetId":4465590}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Import Libraries and Load Tokenizer\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, AdamW, get_scheduler\nfrom datasets import load_dataset\nimport pandas as pd\nimport wandb\nfrom torch.cuda.amp import autocast, GradScaler\nimport gc\nfrom tqdm import tqdm\n\n# Initialize WandB in offline mode\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_api_key\")\n\nwandb.login(key=secret_value_0)\nwandb.init(project=\"DeBERTa-Fake-News\", config={\"epochs\": 3, \"batch_size\": 32, \"lr\": 1e-5}, mode=\"offline\")\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\n# Free GPU cache\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Load DeBERTa tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Load Datasets\n# Load dataset from Hugging Face for pre-training\nds = load_dataset(\"Salesforce/wikitext\", \"wikitext-103-v1\", split=\"train\")\npretrain_texts = ds[\"text\"][:int(0.05 * len(ds[\"text\"]))]  # Use 10% of Wikitext-103\npretrain_df = pd.DataFrame({\"text\": pretrain_texts, \"label\": [0] * len(pretrain_texts)})\n\n# Load dataset from CSV (WELFake) for fine-tuning\nwelfake_df = pd.read_csv(\"/kaggle/input/welfake-dataset-for-fake-news/WELFake_Dataset.csv\", usecols=[\"text\", \"label\"], dtype={\"label\": str})\n\n# Ensure labels are numeric & clean\nwelfake_df[\"label\"] = welfake_df[\"label\"].str.replace(r\"[^\\d]\", \"\", regex=True).str.strip()\nwelfake_df = welfake_df[welfake_df[\"label\"] != \"\"]  # Remove empty values\nwelfake_df[\"label\"] = welfake_df[\"label\"].astype(int)  # Convert to int for PyTorch\nprint(\"Data loading complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:36:46.803791Z","iopub.execute_input":"2025-03-30T02:36:46.804075Z","iopub.status.idle":"2025-03-30T02:37:02.583859Z","shell.execute_reply.started":"2025-03-30T02:36:46.804054Z","shell.execute_reply":"2025-03-30T02:37:02.582942Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8367e3bc7f64ca39d390dfb20d3f819"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/722k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a712cf012bf4ccdbafa6017ab2b90a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe5e9660b6c4053a2e63ba2f8e5fcca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/156M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7addce52b45742c2951fc8649221d4cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/655k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df37888a8d68490faf64b2c0924ad2e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"044937c06238440b80a971feceb339ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75b2dd984ac2450ca6acdab9208c1322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c8a4d7b8434bfaa6dd9b3f0c3a8702"}},"metadata":{}},{"name":"stdout","text":"Data loading complete!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Define Dataset Classes\nclass MLMDataset(Dataset):\n    def __init__(self, texts, max_len=128):\n        self.encodings = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\")\n        self.labels = self.encodings.input_ids.clone()\n        rand = torch.rand(self.labels.shape)\n        mask_arr = (rand < 0.15) * (self.labels != tokenizer.pad_token_id) * (self.labels != tokenizer.cls_token_id) * (self.labels != tokenizer.sep_token_id)\n        self.encodings.input_ids[mask_arr] = tokenizer.mask_token_id\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return {key: val[idx] for key, val in self.encodings.items()}, self.labels[idx]\n\nclass FakeNewsDataset(Dataset):\n    def __init__(self, df, max_len=256):\n        self.labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n        self.encodings = tokenizer(df[\"text\"].astype(str).tolist(), padding=\"max_length\", truncation=True, \n                                   max_length=max_len, return_tensors=\"pt\")\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return {key: val[idx] for key, val in self.encodings.items() if key != \"token_type_ids\"}, self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:37:06.314463Z","iopub.execute_input":"2025-03-30T02:37:06.314799Z","iopub.status.idle":"2025-03-30T02:37:06.328452Z","shell.execute_reply.started":"2025-03-30T02:37:06.314769Z","shell.execute_reply":"2025-03-30T02:37:06.327481Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Cell 4: Define DeBERTa Model\nclass DeBERTaClassifier(nn.Module):\n    def __init__(self, model_name=\"microsoft/deberta-v3-base\", num_labels=2):\n        super(DeBERTaClassifier, self).__init__()\n        self.deberta = AutoModel.from_pretrained(model_name)\n        self.deberta.gradient_checkpointing_enable()\n        self.classifier = nn.Linear(self.deberta.config.hidden_size, num_labels)\n        self.mlm_head = nn.Linear(self.deberta.config.hidden_size, self.deberta.config.vocab_size)  # MLM head for pretraining\n    \n    def forward(self, input_ids, attention_mask, mlm=False):\n        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n        if mlm:\n            return self.mlm_head(outputs.last_hidden_state)\n        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:37:08.944800Z","iopub.execute_input":"2025-03-30T02:37:08.945077Z","iopub.status.idle":"2025-03-30T02:37:08.950962Z","shell.execute_reply.started":"2025-03-30T02:37:08.945055Z","shell.execute_reply":"2025-03-30T02:37:08.950285Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Cell 5: Initialize Model, Optimizer, and Scheduler\nmodel = DeBERTaClassifier().to(device)\noptimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\ncriterion = nn.CrossEntropyLoss()\n\n# Learning rate scheduler\nnum_training_steps = 3 * len(welfake_df) // 32  # Adjusted for batch size 32\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n\nscaler = GradScaler()\n\n# Log model details to WandB\nwandb.watch(model, log=\"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:46:22.373119Z","iopub.execute_input":"2025-03-30T02:46:22.373437Z","iopub.status.idle":"2025-03-30T02:46:24.462679Z","shell.execute_reply.started":"2025-03-30T02:46:22.373416Z","shell.execute_reply":"2025-03-30T02:46:24.461798Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-9e1bdd0616b0>:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Check if multiple GPUs are available\nmulti_gpu = torch.cuda.device_count() > 1\nif multi_gpu:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:37:37.266139Z","iopub.execute_input":"2025-03-30T02:37:37.267341Z","iopub.status.idle":"2025-03-30T02:37:37.274364Z","shell.execute_reply.started":"2025-03-30T02:37:37.267289Z","shell.execute_reply":"2025-03-30T02:37:37.273059Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 6: Pre-training Loop\ndef pretrain_model(model, train_loader, epochs=1):\n    model.train()\n    mlm_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n    \n    for epoch in range(epochs):\n        total_loss = 0\n        progress_bar = tqdm(train_loader, desc=f\"Pretraining Epoch {epoch+1}\")\n        \n        for batch in progress_bar:\n            inputs, labels = batch\n            inputs = {key: val.to(device) for key, val in inputs.items()}\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            \n            with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n                outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], mlm=True)\n                loss = mlm_criterion(outputs.view(-1, model.deberta.config.vocab_size), labels.view(-1))\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            total_loss += loss.item()\n            progress_bar.set_postfix(loss=total_loss / len(train_loader))\n        \n        # Log loss per epoch to WandB\n        wandb.log({\"Pretrain Epoch Loss\": total_loss / len(train_loader)})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:46:28.211192Z","iopub.execute_input":"2025-03-30T02:46:28.211575Z","iopub.status.idle":"2025-03-30T02:46:28.219678Z","shell.execute_reply.started":"2025-03-30T02:46:28.211531Z","shell.execute_reply":"2025-03-30T02:46:28.218793Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Cell 7: Run Pre-training\npretrain_dataset = MLMDataset(pretrain_texts)\npretrain_loader = DataLoader(pretrain_dataset, batch_size=32, shuffle=True)\npretrain_model(model, pretrain_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T02:46:30.418320Z","iopub.execute_input":"2025-03-30T02:46:30.418706Z"}},"outputs":[{"name":"stderr","text":"Pretraining Epoch 1:  72%|███████▏  | 2038/2815 [1:35:52<36:33,  2.82s/it, loss=1.84]  ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"save_path = \"/kaggle/working/deberta_pretrained_checkpoint.pth\"\ntorch.save(model.state_dict(), save_path)\nprint(f\"Checkpoint saved at: {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:26:19.368159Z","iopub.execute_input":"2025-03-30T04:26:19.368534Z","iopub.status.idle":"2025-03-30T04:26:21.433145Z","shell.execute_reply.started":"2025-03-30T04:26:19.368509Z","shell.execute_reply":"2025-03-30T04:26:21.432302Z"}},"outputs":[{"name":"stdout","text":"Checkpoint saved at: /kaggle/working/deberta_pretrained_checkpoint.pth\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Cell 8: Fine-tuning Loop\ndef fine_tune_model(model, train_loader):\n    model.train()\n    total_loss, correct, total = 0, 0, 0\n    progress_bar = tqdm(train_loader, desc=\"Fine-tuning Epoch 1\")\n    \n    for batch in progress_bar:\n        inputs, labels = batch\n        inputs = {key: val.to(device) for key, val in inputs.items()}\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        with torch.amp.autocast(\"cuda\"):\n            outputs = model(**inputs)\n            loss = criterion(outputs, labels)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        lr_scheduler.step()\n        \n        # Compute Accuracy\n        preds = torch.argmax(outputs, dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        total_loss += loss.item()\n        progress_bar.set_postfix(loss=total_loss / (total + 1e-8), accuracy=correct / total)\n\n    # Log fine-tuning loss and accuracy to WandB\n    wandb.log({\"Fine-tune Loss\": total_loss / len(train_loader), \"Fine-tune Accuracy\": correct / total})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:26:54.361047Z","iopub.execute_input":"2025-03-30T04:26:54.361345Z","iopub.status.idle":"2025-03-30T04:26:54.368919Z","shell.execute_reply.started":"2025-03-30T04:26:54.361322Z","shell.execute_reply":"2025-03-30T04:26:54.368098Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Cell 9: Run Fine-tuning\ntrain_dataset = FakeNewsDataset(welfake_df)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nfine_tune_model(model, train_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T04:26:57.703043Z","iopub.execute_input":"2025-03-30T04:26:57.703340Z","iopub.status.idle":"2025-03-30T05:04:35.517510Z","shell.execute_reply.started":"2025-03-30T04:26:57.703316Z","shell.execute_reply":"2025-03-30T05:04:35.516041Z"}},"outputs":[{"name":"stderr","text":"Fine-tuning Epoch 1: 100%|██████████| 2255/2255 [36:17<00:00,  1.04it/s, accuracy=0.974, loss=0.00176]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Cell 10: Save Fine-Tuned Model\nmodel_save_path = \"./deberta_finetuned.pth\"\ntorch.save(model.state_dict(), model_save_path)\n\n# Log model checkpoint to WandB\nwandb.save(model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:04:46.770249Z","iopub.execute_input":"2025-03-30T05:04:46.770550Z","iopub.status.idle":"2025-03-30T05:04:48.785444Z","shell.execute_reply.started":"2025-03-30T05:04:46.770528Z","shell.execute_reply":"2025-03-30T05:04:48.784588Z"}},"outputs":[{"name":"stdout","text":"Model saved to ./deberta_finetuned.pth\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Cell 11: Model Evaluation and Testing\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, matthews_corrcoef, confusion_matrix\n\ndef evaluate_model(model, test_loader):\n    model.eval()\n    total_loss, correct, total = 0, 0, 0\n    all_preds, all_labels, all_probs = [], [], []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating Model\"):\n            inputs, labels = batch\n            inputs = {key: val.to(device) for key, val in inputs.items()}\n            labels = labels.to(device)\n            \n            outputs = model(**inputs)\n            loss = criterion(outputs, labels)\n\n            # Compute predictions & probabilities\n            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Probability of class 1\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            labels = labels.cpu().numpy()\n\n            # Store batch results\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n            all_probs.extend(probs)\n\n            correct += (preds == labels).sum()\n            total += labels.shape[0]\n            total_loss += loss.item()\n    \n    avg_loss = total_loss / len(test_loader)\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, zero_division=0)\n    recall = recall_score(all_labels, all_preds, zero_division=0)\n    f1 = f1_score(all_labels, all_preds, zero_division=0)\n    roc_auc = roc_auc_score(all_labels, all_probs)\n    logloss = log_loss(all_labels, all_probs)\n    mcc = matthews_corrcoef(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds)\n\n    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4%}, F1 Score: {f1:.4f}\")\n\n    # Log evaluation results to WandB\n    wandb.log({\n        \"Test Loss\": avg_loss,\n        \"Test Accuracy\": accuracy,\n        \"Test Precision\": precision,\n        \"Test Recall\": recall,\n        \"Test F1 Score\": f1,\n        \"Test ROC AUC\": roc_auc,\n        \"Test Log Loss\": logloss,\n        \"Test MCC\": mcc,\n        \"Test Confusion Matrix\": cm.tolist()\n    })\n\n# Run Evaluation\ntest_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\nevaluate_model(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T05:04:52.066100Z","iopub.execute_input":"2025-03-30T05:04:52.066395Z"}},"outputs":[{"name":"stderr","text":"Evaluating Model:  66%|██████▌   | 1493/2255 [16:48<08:33,  1.49it/s]","output_type":"stream"}],"execution_count":null}]}